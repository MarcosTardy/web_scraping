{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b822ba",
   "metadata": {},
   "source": [
    "## Exercici 1\n",
    "### Realitza web scraping de dues de les tres pàgines web proposades utilitzant BeautifulSoup primer i Selenium després.\n",
    "http://quotes.toscrape.com\n",
    "\n",
    "https://www.bolsamadrid.es\n",
    "\n",
    "www.wikipedia.es "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3bc02d",
   "metadata": {},
   "source": [
    "## 1.1. BeautifoulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3aee21",
   "metadata": {},
   "source": [
    "### 1.1.1. Quotes.toscrape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ec913fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://quotes.toscrape.com\" \n",
    "page = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56c33778",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(class_='container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb443074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('title').string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d931caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote = results.find_all(\"div\", class_=\"quote\", itemscope=\"\")\n",
    "len(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac74b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "J.K. Rowling\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Albert Einstein\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Jane Austen\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Marilyn Monroe\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "Albert Einstein\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "André Gide\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Thomas A. Edison\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Eleanor Roosevelt\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "Steve Martin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in quote:\n",
    "    cita = i.find(\"span\", class_=\"text\")\n",
    "    autor = i.find(\"small\", class_=\"author\")\n",
    "    print(cita.text.strip())\n",
    "    print(autor.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73f017",
   "metadata": {},
   "source": [
    "### 1.1.2. Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb4a0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://es.wikipedia.org/wiki/Estadio_Ol%C3%ADmpico_Llu%C3%ADs_Companys\"\n",
    "page = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f06eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(\"div\", class_=\"mw-page-container-inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39c6676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadio Olímpico Lluís Companys - Wikipedia, la enciclopedia libre\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('title').string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f12231a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Estadio Olímpico Lluís Companys (oficialmente hasta 2001, Estadio Olímpico de Montjuïc; en catalán: Estadi Olímpic Lluís Companys) es un recinto deportivo de titularidad municipal ubicado en la montaña de Montjuic del distrito Sants-Montjuïc, en Barcelona, España. \n",
      "\n",
      "Inauguró el estadio original el rey Alfonso XIII el 20 de mayo de 1929, un día después de la inauguración de la Exposición Internacional.[5]​ Con motivo de los Juegos Olímpicos de 1992, el estadio se reconstruyó prácticamente en su totalidad (1985-1989) y se reinauguró 60 años después como «estadio olímpico», el 8 de septiembre de 1989, por el también rey Juan Carlos I.[6]​\n",
      "\n",
      "Diseñado por el arquitecto barcelonés Pere Domènech i Roura, hijo del arquitecto modernista Lluís Domènech i Montaner,[7]​ se proyectó para albergar unos futuros Juegos Olímpicos que, tras cuatro intentos de candidatura, llegaron a Barcelona 63 años después.[8]​ La configuración del graderío del recinto estaba compuesto por dos semicírculos que enlazaban dos rectas, siguiendo el estilo de las construcciones romanas de circos y anfiteatros, en cuyo interior albergaba la pista de atletismo y el campo deportivo con orientación norte-sur, de 208,5 m x 109 m.[9]​ Tuvo un coste en la época de 65 millones de pesetas[10]​ y tenía una capacidad de 60 000 espectadores, el segundo más grande del mundo en esa época,[11]​ solo superado por el Estadio de Wembley, con capacidad para 100 000 espectadores.\n",
      "\n",
      "Se iniciaron las obras el 5 de abril de 1927 con la colocación de la primera piedra.[12]​ Lo inauguró el 20 de mayo de 1929 el rey Alfonso XIII con motivo de la Exposición Internacional de Barcelona, de cuya sección deportiva fue sede.[13]​ Entre los actos de inauguración se disputó un partido amistoso de fútbol entre un combinado de jugadores de los equipos barceloneses y el Bolton Wanderers, y un partido amistoso de rugby entre las selecciones de España y de Italia.\n",
      "\n",
      "Acogió durante ese primer año varios partidos de la primera edición del Campeonato Nacional de Liga de Primera División (1928-29) con los tres clubes barceloneses de la categoría como locales (Fútbol Club Barcelona, Club Deportivo Europa y Real Club Deportivo Espanyol).\n",
      "\n",
      "El 19 de julio de 1936 estaba previsto que comenzara en el estadio la Olimpiada Popular, que se suspendió a causa del estallido de la guerra civil española.\n",
      "\n",
      "Fue la sede principal de los Juegos Mediterráneos de 1955,. Acogió las ceremonias de inauguración y clausura y las pruebas de atletismo, equitación, fútbol y hockey hierba.\n",
      "\n",
      "En 1957, el estadio acogió la única Final de Copa del Generalísimo en la que se han enfrentado el Fútbol Club Barcelona y el Real Club Deportivo Espanyol, los dos grandes clubes de la «Ciudad Condal». El derbi barcelonés finalizó con victoria azulgrana por 1-0.\n",
      "\n",
      "En 1982, fue escenario durante dos meses de los ensayos para la ceremonia inaugural del Mundial España 82, que se celebró en el Camp Nou y en la que intervinieron más de 3000 estudiantes de varios colegios salesianos de Barcelona.\n",
      "\n",
      "Con la concesión a Barcelona, el 17 de octubre de 1986, de la organización de los Juegos Olímpicos de 1992, se acometió la reconstrucción del estadio a cargo del equipo de arquitectos Correa-Milà-Margarit-Buxadé, con la participación del italiano Vittorio Gregotti.[14]​\n",
      "\n",
      "Las obras comenzaron a finales de 1985.[15]​ El estadio se vació completamente y solo se conservaron las fachadas exteriores (aunque no fue posible salvar la fachada oeste, cuya conservación contemplaba el proyecto, y debió reconstruirse). Se levantaron unas nuevas graderías para un aforo total de 55 926 espectadores. El nivel se rebajó 11 metros y la piedra que se extrajo, piedra de Montjuïc de excelente calidad, se aprovechó para la construcción del Templo de la Sagrada Familia.\n",
      "\n",
      "El 8 de septiembre de 1989 el rey Juan Carlos I lo inauguró como «Estadio Olímpico de Montjuic» con motivo de la Copa del Mundo de Atletismo de 1989, y tres años más tarde fue escenario de las ceremonias de inauguración y clausura de los mencionados Juegos Olímpicos de 1992 y de las pruebas de atletismo. También fue el escenario de las ceremonias de inauguración y clausura y de las pruebas de atletismo de los Juegos Paralímpicos. Para la celebración de estos eventos se instalaron provisionalmente 11 081 asientos adicionales, que se reitiraron a la finalización de los mismos.\n",
      "\n",
      "Desde agosto de 1997 hasta mayo de 2009, el Real Club Deportivo Espanyol disputó sus partidos como local en este estadio, proveniente del Estadio de Sarriá y hasta la inauguración de su nuevo Estadio Cornellá-El Prat. Montjuïc es además, uno de los trece estadios españoles catalogados como de categoría 4 de la UEFA, lo que lo habilita para acoger finales de competiciones futbolísticas continentales.\n",
      "\n",
      "\n",
      "\n",
      "La selección española ha jugado en este estadio ocho de los dieciocho encuentros internacionales que ha disputado en Barcelona. España tiene un balance de cuatro victorias, tres empates y una derrota. La victoria por 2–1 ante Perú, del 18 de febrero de 2004, es hasta el momento, su último encuentro disputado en la ciudad condal.[16]​\n",
      "\n",
      "Las líneas del bus urbano de Barcelona con parada en la avenida de l'Estadi cerca del Estadio Olímpico Lluís Companys son:\n",
      "\n",
      "Las estaciones del Metro de Barcelona más próximas al estadio son la de Poble Sec (L3) y la de Espanya (L1 y L3), esta última también con parada de la línea Llobregat-Anoia de Ferrocarriles de la Generalidad de Cataluña.\n",
      "\n",
      "También está muy cerca del estadio la estación de Parc de Montjuïc del Funicular de Montjuïc, que comunica con la estación de Paral·lel del metro (L3).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = soup.find('main', {'id': 'content'}) #És el que conté tot el que volem\n",
    "\n",
    "# Busca tots els paràgrafs\n",
    "parts_text = text.find_all('p')\n",
    "\n",
    "# Per printejar el contingut\n",
    "for i in parts_text:\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc124bb",
   "metadata": {},
   "source": [
    "## 1.2. Web scrapping amb Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cc5cf",
   "metadata": {},
   "source": [
    "### 1.2.1. Quotes.toscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6eae9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f1096fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() #Obre chrome\n",
    "driver.get(\"http://quotes.toscrape.com\") #Busca enllaç web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a33f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = driver.find_elements(By.CLASS_NAME, \"text\") #Busca per nom de la classe \"text\"\n",
    "# La var \"frase\" emmagatzema totes les instàncies amb nom de la classe \"text\"\n",
    "autor = driver.find_elements(By.CLASS_NAME, \"author\")# Busca per nom de la classe \"author\"\n",
    "# La var \"autor\" emmagatzema totes les instàncies amb nom de la classe \"author\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4bda588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Albert Einstein\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "J.K. Rowling\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Albert Einstein\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Jane Austen\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Marilyn Monroe\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "Albert Einstein\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "André Gide\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Thomas A. Edison\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Eleanor Roosevelt\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "Steve Martin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(frase, autor): #Bucle doble dins la llista frase i la llista autor\n",
    "    frase_text = i.text.strip() \n",
    "    autor_text = j.text.strip()\n",
    "    print(frase_text)\n",
    "    print(autor_text)\n",
    "    print()  # Una linea en blanc per separar les frases i els autors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9021b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit() #Tanca el navegador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88e4b6",
   "metadata": {},
   "source": [
    "### 1.2.2. Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "967b08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() #Obre chrome\n",
    "driver.get(\"https://es.wikipedia.org/wiki/Estadio_Ol%C3%ADmpico_Llu%C3%ADs_Companys\") #Busca enllaç web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "74ec4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "par = driver.find_elements(By.TAG_NAME, \"p\") \n",
    "# La var \"par\" emmagatzema tots els paràgrafs de la pàgina web\n",
    "titol = driver.find_elements(By.TAG_NAME, \"h2\")\n",
    "# La var \"titol\" emmagatzema tots els titols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "920251e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenidos\n",
      "El Estadio Olímpico Lluís Companys (oficialmente hasta 2001, Estadio Olímpico de Montjuïc; en catalán: Estadi Olímpic Lluís Companys) es un recinto deportivo de titularidad municipal ubicado en la montaña de Montjuic del distrito Sants-Montjuïc, en Barcelona, España.\n",
      "\n",
      "Historia\n",
      "Inauguró el estadio original el rey Alfonso XIII el 20 de mayo de 1929, un día después de la inauguración de la Exposición Internacional.5 Con motivo de los Juegos Olímpicos de 1992, el estadio se reconstruyó prácticamente en su totalidad (1985-1989) y se reinauguró 60 años después como «estadio olímpico», el 8 de septiembre de 1989, por el también rey Juan Carlos I.6\n",
      "\n",
      "Eventos deportivos\n",
      "Diseñado por el arquitecto barcelonés Pere Domènech i Roura, hijo del arquitecto modernista Lluís Domènech i Montaner,7 se proyectó para albergar unos futuros Juegos Olímpicos que, tras cuatro intentos de candidatura, llegaron a Barcelona 63 años después.8 La configuración del graderío del recinto estaba compuesto por dos semicírculos que enlazaban dos rectas, siguiendo el estilo de las construcciones romanas de circos y anfiteatros, en cuyo interior albergaba la pista de atletismo y el campo deportivo con orientación norte-sur, de 208,5 m x 109 m.9 Tuvo un coste en la época de 65 millones de pesetas10 y tenía una capacidad de 60 000 espectadores, el segundo más grande del mundo en esa época,11 solo superado por el Estadio de Wembley, con capacidad para 100 000 espectadores.\n",
      "\n",
      "Eventos musicales\n",
      "Se iniciaron las obras el 5 de abril de 1927 con la colocación de la primera piedra.12 Lo inauguró el 20 de mayo de 1929 el rey Alfonso XIII con motivo de la Exposición Internacional de Barcelona, de cuya sección deportiva fue sede.13 Entre los actos de inauguración se disputó un partido amistoso de fútbol entre un combinado de jugadores de los equipos barceloneses y el Bolton Wanderers, y un partido amistoso de rugby entre las selecciones de España y de Italia.\n",
      "\n",
      "Otros eventos\n",
      "Acogió durante ese primer año varios partidos de la primera edición del Campeonato Nacional de Liga de Primera División (1928-29) con los tres clubes barceloneses de la categoría como locales (Fútbol Club Barcelona, Club Deportivo Europa y Real Club Deportivo Espanyol).\n",
      "\n",
      "Transporte público\n",
      "El 19 de julio de 1936 estaba previsto que comenzara en el estadio la Olimpiada Popular, que se suspendió a causa del estallido de la guerra civil española.\n",
      "\n",
      "Véase también\n",
      "Fue la sede principal de los Juegos Mediterráneos de 1955,. Acogió las ceremonias de inauguración y clausura y las pruebas de atletismo, equitación, fútbol y hockey hierba.\n",
      "\n",
      "Referencias\n",
      "En 1957, el estadio acogió la única Final de Copa del Generalísimo en la que se han enfrentado el Fútbol Club Barcelona y el Real Club Deportivo Espanyol, los dos grandes clubes de la «Ciudad Condal». El derbi barcelonés finalizó con victoria azulgrana por 1-0.\n",
      "\n",
      "Notas\n",
      "En 1982, fue escenario durante dos meses de los ensayos para la ceremonia inaugural del Mundial España 82, que se celebró en el Camp Nou y en la que intervinieron más de 3000 estudiantes de varios colegios salesianos de Barcelona.\n",
      "\n",
      "Enlaces externos\n",
      "Con la concesión a Barcelona, el 17 de octubre de 1986, de la organización de los Juegos Olímpicos de 1992, se acometió la reconstrucción del estadio a cargo del equipo de arquitectos Correa-Milà-Margarit-Buxadé, con la participación del italiano Vittorio Gregotti.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(titol, par): #Bucle doble dins la llista frase i la llista autor\n",
    "    titol_text = i.text.strip().replace(\"[editar]\", \"\") \n",
    "    par_text = j.text.strip()\n",
    "    print(titol_text)\n",
    "    print(par_text)\n",
    "    print()  # Una linea en blanc per separar les frases i els autors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bb9849eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit() #Tanca el navegador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d5264",
   "metadata": {},
   "source": [
    "## - Exercici 2\n",
    "### Documenta en un Word el teu conjunt de dades generat amb la informació que tenen els diferents arxius de Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a314df",
   "metadata": {},
   "source": [
    "### Quotes.scrape.com\n",
    "##### Context\n",
    "A website that lists quotes from famous people. It has many endpoints showing the quotes in many different ways, each of them including new scraping challenges for you, as described below.\n",
    "##### Content\n",
    "Quote: 10 quotes of famous people\n",
    "Author: name of the famous person  \n",
    "### Wikipedia\n",
    "##### Context\n",
    "Wikipedia és una enciclopèdia lliure, poliglota i editada de manera col·laboratiba. Dins de wikipedia s’ha buscat informació obre el Camp Olímpic Lluís Companys, seu del FcBarcelona durant aquest any, però que també ha tingut equips com l’Espanyol.\n",
    "##### Content\n",
    "Títols: \n",
    "\n",
    "•\tContenidos\n",
    "•\tHistoria\n",
    "•\tEventos deportivos\n",
    "•\tEventos musicales \n",
    "•\tOtros eventos\n",
    "•\tTransporte público \n",
    "•\tVéase también\n",
    "•\tReferencias\n",
    "•\tNotas\n",
    "•\tEnlaces externos\n",
    "\n",
    "Paràgrafs: Contingut de cada paràgraf del text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6643254",
   "metadata": {},
   "source": [
    "## - Exercici 3\n",
    "### Tria una pàgina web que tu vulguis i realitza web scraping mitjançant la llibreria Selenium primer i Scrapy després. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90645851",
   "metadata": {},
   "source": [
    "He decidit realitzar web scraping a la classificació actual de la lliga. Vull buscar els noms del equips ordenats de primer a últim segons la classificació."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92068a",
   "metadata": {},
   "source": [
    "### 3.1. Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "12fa4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() #Obre chrome\n",
    "driver.get(\"https://www.google.com/search?gs_ssp=eJzj4tDP1TewTC-sMGD0YstJzMlMTwQAMXYFgg&q=laliga&rlz=1C1CHBF_esES924ES924&oq=&gs_lcrp=EgZjaHJvbWUqCQgHEC4YJxjqAjIJCAAQLhgnGOoCMgkIARAjGCcY6gIyCQgCECMYJxjqAjIJCAMQIxgnGOoCMgkIBBAjGCcY6gIyCQgFECMYJxjqAjIJCAYQIxgnGOoCMgkIBxAuGCcY6gLSAQo1NzQwMjNqMGo3qAIIsAIB&sourceid=chrome&ie=UTF-8#sie=lg;/g/11khrmf0s3;2;/m/09gqx;st;fp;1;;;\") #Busca enllaç web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0b8b1ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team = driver.find_elements(By.CLASS_NAME, \"e6E1Yd\") \n",
    "# La var \"team\" emmagatzema tots els equips de la lliga ordenats per posició"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e16b8dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Real Madrid\n",
      "2 Girona\n",
      "3 Barcelona\n",
      "4 Atlético Madrid\n",
      "5 Athletic\n",
      "6 Real Sociedad\n",
      "7 Betis\n",
      "8 Rayo Vallecano\n",
      "9 Valencia C. F.\n",
      "10 U. D. Las Palmas\n",
      "11 Getafe\n",
      "12 Osasuna\n",
      "13 Cádiz\n",
      "14 Sevilla\n",
      "15 R.C.D. Mallorca\n",
      "16 Villarreal\n",
      "17 Alavés\n",
      "18 Celta de Vigo\n",
      "19 Granada\n",
      "20 Almería\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "for i in team:\n",
    "    print(n, i.text)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0990042",
   "metadata": {},
   "source": [
    "### 3.2. Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c93871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30fb9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiSpider(scrapy.Spider):\n",
    "    name = 'clasificacion'\n",
    "    start_urls = ['https://www.marca.com/futbol/primera-division/clasificacion.html']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Crear una lista para almacenar los resultados\n",
    "        resultados = []\n",
    "\n",
    "        elementos = response.xpath('//th[@class=\"ue-c-table-ranking__th ue-table-ranking-extended is-main\"]')\n",
    "\n",
    "        for elemento in elementos:\n",
    "            equipo_nombre = elemento.xpath('.//span[@class=\"ue-c-table-ranking__team-name\"]/text()').get()\n",
    "            resultados.append({'Nombre del equipo': equipo_nombre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "345493ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled error in Deferred:\n",
      "2023-10-15 15:17:52 [twisted] CRITICAL: Unhandled error in Deferred:\n",
      "2023-10-15 15:17:52 [twisted] CRITICAL: Unhandled error in Deferred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 265, in crawl\n",
      "    return self._crawl(crawler, *args, **kwargs)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 269, in _crawl\n",
      "    d = crawler.crawl(*args, **kwargs)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1947, in unwindGenerator\n",
      "    return _cancellableInlineCallbacks(gen)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1857, in _cancellableInlineCallbacks\n",
      "    _inlineCallbacks(None, gen, status, _copy_context())\n",
      "--- <exception caught here> ---\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1697, in _inlineCallbacks\n",
      "    result = context.run(gen.send, result)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 158, in crawl\n",
      "    self.engine = self._create_engine()\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 172, in _create_engine\n",
      "    return ExecutionEngine(self, lambda _: self.stop())\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\engine.py\", line 99, in __init__\n",
      "    self.downloader: Downloader = downloader_cls(crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\__init__.py\", line 97, in __init__\n",
      "    DownloaderMiddlewareManager.from_crawler(crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\middleware.py\", line 90, in from_crawler\n",
      "    return cls.from_settings(crawler.settings, crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\middleware.py\", line 67, in from_settings\n",
      "    mw = create_instance(mwcls, settings, crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 188, in create_instance\n",
      "    instance = objcls.from_crawler(crawler, *args, **kwargs)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 157, in from_crawler\n",
      "    return cls(crawler.settings)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 150, in __init__\n",
      "    self.exceptions_to_retry = tuple(\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 151, in <genexpr>\n",
      "    load_object(x) if isinstance(x, str) else x\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "    \n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\web\\client.py\", line 24, in <module>\n",
      "    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\endpoints.py\", line 63, in <module>\n",
      "    from twisted.python.systemd import ListenFDs\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\python\\systemd.py\", line 18, in <module>\n",
      "    from attrs import Factory, define\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attrs\\__init__.py\", line 3, in <module>\n",
      "    from attr import (\n",
      "builtins.ImportError: cannot import name 'AttrsInstance' from 'attr' (C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attr\\__init__.py)\n",
      "\n",
      "2023-10-15 15:17:52 [twisted] CRITICAL: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 147, in __init__\n",
      "    self.exceptions_to_retry = self.__getattribute__(\"EXCEPTIONS_TO_RETRY\")\n",
      "AttributeError: 'RetryMiddleware' object has no attribute 'EXCEPTIONS_TO_RETRY'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1697, in _inlineCallbacks\n",
      "    result = context.run(gen.send, result)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 158, in crawl\n",
      "    self.engine = self._create_engine()\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 172, in _create_engine\n",
      "    return ExecutionEngine(self, lambda _: self.stop())\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\engine.py\", line 99, in __init__\n",
      "    self.downloader: Downloader = downloader_cls(crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\__init__.py\", line 97, in __init__\n",
      "    DownloaderMiddlewareManager.from_crawler(crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\middleware.py\", line 90, in from_crawler\n",
      "    return cls.from_settings(crawler.settings, crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\middleware.py\", line 67, in from_settings\n",
      "    mw = create_instance(mwcls, settings, crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 188, in create_instance\n",
      "    instance = objcls.from_crawler(crawler, *args, **kwargs)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 157, in from_crawler\n",
      "    return cls(crawler.settings)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 150, in __init__\n",
      "    self.exceptions_to_retry = tuple(\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 151, in <genexpr>\n",
      "    load_object(x) if isinstance(x, str) else x\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\web\\client.py\", line 24, in <module>\n",
      "    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\endpoints.py\", line 63, in <module>\n",
      "    from twisted.python.systemd import ListenFDs\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\python\\systemd.py\", line 18, in <module>\n",
      "    from attrs import Factory, define\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attrs\\__init__.py\", line 3, in <module>\n",
      "    from attr import (\n",
      "ImportError: cannot import name 'AttrsInstance' from 'attr' (C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attr\\__init__.py)\n",
      "2023-10-15 15:17:52 [twisted] CRITICAL: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 147, in __init__\n",
      "    self.exceptions_to_retry = self.__getattribute__(\"EXCEPTIONS_TO_RETRY\")\n",
      "AttributeError: 'RetryMiddleware' object has no attribute 'EXCEPTIONS_TO_RETRY'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\defer.py\", line 1697, in _inlineCallbacks\n",
      "    result = context.run(gen.send, result)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 158, in crawl\n",
      "    self.engine = self._create_engine()\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\crawler.py\", line 172, in _create_engine\n",
      "    return ExecutionEngine(self, lambda _: self.stop())\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\engine.py\", line 99, in __init__\n",
      "    self.downloader: Downloader = downloader_cls(crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\__init__.py\", line 97, in __init__\n",
      "    DownloaderMiddlewareManager.from_crawler(crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\middleware.py\", line 90, in from_crawler\n",
      "    return cls.from_settings(crawler.settings, crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\middleware.py\", line 67, in from_settings\n",
      "    mw = create_instance(mwcls, settings, crawler)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 188, in create_instance\n",
      "    instance = objcls.from_crawler(crawler, *args, **kwargs)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 157, in from_crawler\n",
      "    return cls(crawler.settings)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 150, in __init__\n",
      "    self.exceptions_to_retry = tuple(\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\downloadermiddlewares\\retry.py\", line 151, in <genexpr>\n",
      "    load_object(x) if isinstance(x, str) else x\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\web\\client.py\", line 24, in <module>\n",
      "    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\endpoints.py\", line 63, in <module>\n",
      "    from twisted.python.systemd import ListenFDs\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\python\\systemd.py\", line 18, in <module>\n",
      "    from attrs import Factory, define\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attrs\\__init__.py\", line 3, in <module>\n",
      "    from attr import (\n",
      "ImportError: cannot import name 'AttrsInstance' from 'attr' (C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attr\\__init__.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 15:17:52 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapybot)\n",
      "2023-10-15 15:17:52 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.1.3 19 Sep 2023), cryptography 41.0.4, Platform Windows-10-10.0.19041-SP0\n",
      "2023-10-15 15:17:52 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-10-15 15:17:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2023-10-15 15:17:52 [scrapy.extensions.telnet] INFO: Telnet Password: ff00af262eed35c6\n",
      "2023-10-15 15:17:52 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-10-15 15:17:52 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2023-10-15 15:17:52 [scrapy.core.downloader.handlers] ERROR: Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\__init__.py\", line 55, in _load_handler\n",
      "    dhcls = load_object(path)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http.py\", line 2, in <module>\n",
      "    from scrapy.core.downloader.handlers.http11 import (\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http11.py\", line 12, in <module>\n",
      "    from twisted.internet.endpoints import TCP4ClientEndpoint\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\endpoints.py\", line 63, in <module>\n",
      "    from twisted.python.systemd import ListenFDs\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\python\\systemd.py\", line 18, in <module>\n",
      "    from attrs import Factory, define\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attrs\\__init__.py\", line 3, in <module>\n",
      "    from attr import (\n",
      "ImportError: cannot import name 'AttrsInstance' from 'attr' (C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attr\\__init__.py)\n",
      "2023-10-15 15:17:52 [scrapy.core.downloader.handlers] ERROR: Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\__init__.py\", line 55, in _load_handler\n",
      "    dhcls = load_object(path)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http.py\", line 2, in <module>\n",
      "    from scrapy.core.downloader.handlers.http11 import (\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http11.py\", line 12, in <module>\n",
      "    from twisted.internet.endpoints import TCP4ClientEndpoint\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\endpoints.py\", line 63, in <module>\n",
      "    from twisted.python.systemd import ListenFDs\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\python\\systemd.py\", line 18, in <module>\n",
      "    from attrs import Factory, define\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attrs\\__init__.py\", line 3, in <module>\n",
      "    from attr import (\n",
      "ImportError: cannot import name 'AttrsInstance' from 'attr' (C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attr\\__init__.py)\n",
      "2023-10-15 15:17:52 [scrapy.core.downloader.handlers] ERROR: Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\__init__.py\", line 55, in _load_handler\n",
      "    dhcls = load_object(path)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\utils\\misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\s3.py\", line 1, in <module>\n",
      "    from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http.py\", line 2, in <module>\n",
      "    from scrapy.core.downloader.handlers.http11 import (\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\scrapy\\core\\downloader\\handlers\\http11.py\", line 12, in <module>\n",
      "    from twisted.internet.endpoints import TCP4ClientEndpoint\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\internet\\endpoints.py\", line 63, in <module>\n",
      "    from twisted.python.systemd import ListenFDs\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\twisted\\python\\systemd.py\", line 18, in <module>\n",
      "    from attrs import Factory, define\n",
      "  File \"C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attrs\\__init__.py\", line 3, in <module>\n",
      "    from attr import (\n",
      "ImportError: cannot import name 'AttrsInstance' from 'attr' (C:\\Users\\marco\\anaconda3\\lib\\site-packages\\attr\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Crea una instancia de CrawlerProcess\n",
    "process = CrawlerProcess()\n",
    "\n",
    "# Agrega tu spider al proceso\n",
    "process.crawl(MiSpider)\n",
    "\n",
    "# Ejecuta el proceso (esto iniciará la spider)\n",
    "process.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac5f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open('output.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab9579ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e031af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
